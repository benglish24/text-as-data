{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694ea3c4-de24-45c1-a8cb-ae3a53f3e8bc",
   "metadata": {},
   "source": [
    "## BERT for Classification\n",
    "\n",
    "*Based on Jay Alammar's [\"A Visual Notebook to Using BERT for the First Time\"](https://github.com/jalammar/jalammar.github.io/blob/master/notebooks/bert/A_Visual_Notebook_to_Using_BERT_for_the_First_Time.ipynb).*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6015b3f7-2a13-48ce-ba83-6c54c099c82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import torch\n",
    "import transformers as ppb # pytorch transformers\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44221b0e-cd0a-4f4e-812e-6ad2a81692e9",
   "metadata": {},
   "source": [
    "Please note that the movie reviews are also available in the `data` folder, so the `dataurl` below could be simply `../data/moviereviews.csv`. (The commented code is there to remind you just how easy it is to save to a CSV file when you use **pandas**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c25233ea-cb1c-4077-984d-6320d6a6f328",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a stirring , funny and finally transporting re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apparently reassembled from the cutting room f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>they presume their audience wo n't sit still f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>this is a visually stunning rumination on love...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jonathan parker 's bartleby should have been t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  1\n",
       "0  a stirring , funny and finally transporting re...  1\n",
       "1  apparently reassembled from the cutting room f...  0\n",
       "2  they presume their audience wo n't sit still f...  0\n",
       "3  this is a visually stunning rumination on love...  1\n",
       "4  jonathan parker 's bartleby should have been t...  1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is simply to keep the load line from getting too long\n",
    "# (You could also break at commas, but this seems cleaner.)\n",
    "dataurl = 'https://github.com/clairett/pytorch-sentiment-classification/raw/master/data/SST2/train.tsv'\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv(dataurl, delimiter='\\t', header=None)\n",
    "\n",
    "# Save the data locally (optional)\n",
    "# df.to_csv(\"../data/moviereviews.csv\")\n",
    "\n",
    "# See the results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71cbeafd-bd19-44cf-9dd2-ea6cb5a6038a",
   "metadata": {},
   "source": [
    "There are approximately 7000 reviews in this dataset. The processing time when building the BERT model is over six minutes. To speed things along, we can work with an initial batch. (Feel free to remove this cap when you work on your own.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fde7005-ebb5-4ba2-8b56-f629012dc8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\n",
       "1    1041\n",
       "0     959\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1 = df[:2000]\n",
    "batch_1[1].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f2aa89-d1e7-42cc-9cce-e04b20c4d5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can toggle between DistilBERT and plain BERT by \n",
    "# commenting/uncommenting the following two lines:\n",
    "\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "#model_class, tokenizer_class, pretrained_weights = (ppb.BertModel, ppb.BertTokenizer, 'bert-base-uncased')\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1921f223-5dee-42da-bccb-8f9864c86642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1037, 18385, 1010, 6057, 1998, 2633, 18276, 2128, 16603, 1997, 5053, 1998, 1996, 6841, 1998, 5687, 5469, 3152, 102]\n"
     ]
    }
   ],
   "source": [
    "# Grab just the texts\n",
    "texts = batch_1[0].tolist()\n",
    "\n",
    "# Convert them to word embedding IDs\n",
    "identified = [tokenizer.encode(x, add_special_tokens=True) for x in texts]\n",
    "\n",
    "# Check the results\n",
    "print(identified[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ace14d44-0175-4b39-81c6-219cb8bd428f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# One-liner using lambda\n",
    "tokenized = batch_1[0].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "# Ask the question: Do these produce the same results?\n",
    "print(tokenized[10] == identified[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375a888d-e815-4c7d-b2cd-ff88d0c9f926",
   "metadata": {},
   "source": [
    "Okay, if we want BERT to process our texts in a single batch, we need them all to be in a single array, and in order for them to be in a single array, they all need to be the same size and for them all to be the same size we need to pad the lists of numbers with zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36b7402e-6638-444c-9982-def442af1919",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 59)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "\n",
    "# What's our array look like?\n",
    "# (How many texts and how \"long\"?)\n",
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd86a4c-9a11-4121-b581-b7b81044fdbc",
   "metadata": {},
   "source": [
    "Having padded our sequences, we need to make sure BERT ignores the zeros, so we create a mask:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6d72c73c-20ae-494c-828b-9d32a33eaa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 59)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ignore zeros\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "\n",
    "# Check to see that shapes match\n",
    "attention_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d42f51ad-287e-4c87-91f7-c8c1219f9a54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or we could do a direct comparison again\n",
    "np.array(padded).shape == attention_mask.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f8661b-82b2-48e5-b9b2-7c917ccb8547",
   "metadata": {},
   "source": [
    "I've got a timer on the process below. On my M1 Macbook Air, it takes about six minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "337b02aa-c247-49d6-807b-0fb62d3bf2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 65.00770401954651\n"
     ]
    }
   ],
   "source": [
    "# We have used Jupyter cell magic before\n",
    "# now we are using the Python time library\n",
    "start_time = time.time()\n",
    "\n",
    "# The actual code\n",
    "input_ids = torch.tensor(padded)  \n",
    "attention_mask = torch.tensor(attention_mask)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "# More time measurement\n",
    "end_time = time.time()\n",
    "execution_time = end_time - start_time\n",
    "print(f\"Execution time: {execution_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13ea8f62-a693-4a82-bacf-33ce1f505d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d954af9-58a9-4776-919a-59a4122582f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_1 = df[:2000]\n",
    "labels = batch_1[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f8b505-25ea-4d05-b10c-aaed1087536b",
   "metadata": {},
   "source": [
    "## Summarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b41519b-ff9a-4fb8-9744-db506133b703",
   "metadata": {},
   "source": [
    "If you are interested in having BERT summarize things for you, check out the [BERT Extractive Summarizer](https://pypi.org/project/bert-extractive-summarizer/) -- and make sure you understand the difference between abstractive and extractive summarizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a54051-9703-4d31-90ba-78d376ba50ac",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
